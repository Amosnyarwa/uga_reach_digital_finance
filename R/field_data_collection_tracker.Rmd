---
title: "Tracker for field data collection"
author: "Anthony Twesigye"
date: "03/09/2021"
output: 
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = paste0(dirname(inputFile), '/field_data_collection_tracker_', format(Sys.Date(), '%Y_%m_%d'),'.html')) })
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = F, message = F)
# read packages
library(tidyverse)
library(lubridate)
library(glue)
library(leaflet)

# read data 
df_settlement_samples_required <- readxl::read_excel("../inputs/samples_settlement_definition.xlsx") %>% 
  mutate(settlement_name = str_replace(string = settlement_name, pattern = "_ii$", replacement = "_II"),
         settlement_name = ifelse(settlement_name == "adjumani", str_to_lower(Name_Zn), settlement_name),
         settlement_name= case_when(settlement_name == "alere" ~ "alere ii",
                                    settlement_name == "ayilo ii" ~ "ayiloii",
                                    settlement_name == "mirieyi" ~ "mireyi",
                                    settlement_name == "mungula 2" ~ "mungula ii",
                                    settlement_name == "pagirinya" ~ "pagrinya",
                                    TRUE ~ settlement_name)) %>% 
  select(settlement_name, smpl_sz)

df_host_samples_required <- readxl::read_excel("../inputs/samples_host_sub_definition.xlsx")%>% 
  select(sub_county_name, smpl_sz)

df_tool_data <- readxl::read_excel("../inputs/UGA2103_Financial_Service_Providers_Assessment_HH_Tool_June2021.xlsx") %>% 
  mutate(uuid = `_uuid`,
         start_date = as_date(start),
         start = as_datetime(start),
         end = as_datetime(end),
         latitude = as.numeric(`_geopoint_latitude`),
         longitude = as.numeric(`_geopoint_longitude`)) %>% 
  filter(consent == "yes",  respondent_age >= 18,
         start_date > as_date("2021-08-29"), 
         point_number != "13m.", 
         !start_date %in% c(as_date("2021-09-08"), as_date("2021-09-09"), 
                            as_date("2021-09-21")),
         !str_detect(string = point_number, pattern = fixed('test', ignore_case = TRUE)),
         !uuid %in% c("27b0ffe2-8d47-4897-b402-1928fd23cfb3",
                      "40d216de-76db-42b7-9105-aea1ce234489",
                      "f2f648df-55d6-4b9d-93ca-aa87c3bc30c7",
                      "4167b891-b1ff-46b1-856b-532dd28e7a1e",
                      "d7bde578-cdc2-4d77-b31b-a15c4cec9d38",
                      "4f3afa4f-a065-4f6d-bd25-9919902f9ce0",
                      "a89d0010-d626-4a4f-8b8c-e83e8fade349",
                      "27ac9f75-3954-4c55-90a3-b5b09984fe7a",
                      "48ee8073-a0d7-460f-9867-304a47bdb1fc",
                      "b0a1c83dcdb24671b9eed78d7a77786f",
                      "c5c9b13aa6cd43338e113d8c647c04ed",
                      "d8936d35-7e1c-48d9-bafa-b25e758c05eb"
         ))
# days that contain data
df_days_for_data_collection <- df_tool_data %>% select(start_date) %>% unique() %>% arrange(start_date) %>% pull()

df_data_support_cl_log <- df_tool_data %>% 
  select(uuid, status,sub_county_name,	settlement_name, latitude,	longitude )
# cleaning log handling
df_cl_log <- read_csv(file = "../inputs/combined_logic_spatial_and_others_checks.csv") %>% 
  mutate(adjust_log = ifelse(is.na(adjust_log), "apply_suggested_change", adjust_log)) %>% 
  left_join(df_data_support_cl_log, by = "uuid")

# change_response logs that affect stats in the data collection progress
cl_log_change_response <- df_cl_log %>% 
  filter(type == "change_response", 
         !is.na(value),
         reviewed == 1, 
         adjust_log != "delete_log", 
         !issue_id %in% c("other_checks", "logic_c_main_language",  "logic_c_internet_awareness") ) %>% 
  select(uuid, name, value)

# updated tool data
df_updated_tool_data <- df_tool_data

# get uuids from cleaning log
uuids_chg_response <- cl_log_change_response %>% pull(uuid) %>% unique()

for (current_uuid in uuids_chg_response) {
  current_uuid_data <- cl_log_change_response %>% 
    filter(uuid == current_uuid) %>% 
    mutate(value = ifelse(name == "enumerator_id", as.numeric(value), value)) %>% 
    pivot_wider(names_from = "name", values_from = "value", uuid)
  print(current_uuid_data)
  # process current updates
  df_current_updated <- df_updated_tool_data %>% 
    rows_update(y = current_uuid_data, by = "uuid")
  # update the parent dataset with current updates
  df_updated_tool_data <- df_current_updated
}

# enumerator performance data
df_enum_performance <- df_updated_tool_data %>% 
  mutate(int.survey_time_interval = lubridate::time_length(end - start, unit = "min"),
         int.survey_time_interval = ceiling(int.survey_time_interval)) 

# change some options in the table
dt_set_options<- function(x){
  DT::datatable(x,
                options = list(
                  autoWidth=F,
                  dom= 't',
                  list(list(width = '20%', targets = list(1,2,3,4,5)))
                )
  )
}

dt_with_modified_options <- function(x){
  DT::datatable(x,
                rownames = FALSE,
                options = list(
                  columnDefs = list(list(className = 'dt-center', targets = list(1,2))),
                  pageLength = 20,
                  initComplete = JS(
                    "function(settings, json) {",
                    "$(this.api().table().header()).css({'background-color': '#333', 'color': '#fff'});",
                    "}")
                )
  )
}

dt_options_fewcols <- function(x){
  DT::datatable(x,
                rownames = FALSE,
                options = list(
                  pageLength = 20,
                  initComplete = JS(
                    "function(settings, json) {",
                    "$(this.api().table().header()).css({'background-color': '#333', 'color': '#fff'});",
                    "}")
                )
  )
}


dt_enum_performance_options <- function(x){
  DT::datatable(x,
                rownames = FALSE,
                filter = 'top',
                options = list(
                  columnDefs = list(list(className = 'dt-center', targets = list(1,2))),
                  pageLength = 50,
                  initComplete = JS(
                    "function(settings, json) {",
                    "$(this.api().table().header()).css({'background-color': '#333', 'color': '#fff'});",
                    "}"),
                  order = list(list(1, 'desc'), list(0, 'asc'), list(3, 'desc'))
                )
  )
}

```

## Summary on the surveys done

>There are **`r nrow(df_updated_tool_data)`** total number of surveys done as of **`r df_days_for_data_collection[length(df_days_for_data_collection)]`**.

### Settlements:  **`r df_updated_tool_data %>% filter(status == "refugee") %>% nrow()`** surveys

```{r, echo = FALSE}
df_refugee_samp_per_settlement <- df_settlement_samples_required %>% 
  group_by(settlement_name) %>% 
  summarise(required_samples = sum(smpl_sz, na.rm = TRUE))

df_cl_surveys_for_deletion <- df_cl_log %>% 
  filter(status == "refugee", type == "remove_survey", reviewed == 1, adjust_log != "delete_log") %>%
  group_by(settlement_name) %>% 
  distinct(uuid) %>%
  summarise(surveys_for_deletion = n())

df_updated_tool_data %>% 
  filter(status == "refugee") %>% 
  group_by(district_name, settlement_name) %>% 
  summarise(number_of_surveys = n()) %>% 
  arrange(district_name) %>% 
  left_join(df_refugee_samp_per_settlement, by = "settlement_name") %>% 
  left_join(df_cl_surveys_for_deletion, by = "settlement_name") %>% 
  mutate(int.surveys_and_deletion = ifelse(is.na(surveys_for_deletion), number_of_surveys, number_of_surveys - surveys_for_deletion),
         remaining_surveys = required_samples - int.surveys_and_deletion ) %>% 
  select(-int.surveys_and_deletion) %>% 
  dt_with_modified_options()

```

### Host community: **`r df_updated_tool_data %>% filter(status == "host_community") %>% nrow()`** surveys

```{r, echo = FALSE}
df_host_samp_per_sub_county <- df_host_samples_required %>% 
  group_by(sub_county_name) %>% 
  summarise(required_samples = sum(smpl_sz, na.rm = TRUE))

df_cl_surveys_for_deletion <- df_cl_log %>% 
  filter(status == "host_community", type == "remove_survey", reviewed == 1, adjust_log != "delete_log") %>%
  group_by(sub_county_name) %>% 
  distinct(uuid) %>%
  summarise(surveys_for_deletion = n())

df_updated_tool_data %>% 
  filter(status == "host_community") %>% 
  group_by(district_name, sub_county_name) %>% 
  summarise(number_of_surveys = n()) %>% 
  arrange(district_name) %>% 
  left_join(df_host_samp_per_sub_county, by = "sub_county_name") %>% 
  left_join(df_cl_surveys_for_deletion, by = "sub_county_name") %>% 
  mutate(int.surveys_and_deletion = ifelse(is.na(surveys_for_deletion), number_of_surveys, number_of_surveys - surveys_for_deletion),
         remaining_surveys = required_samples - int.surveys_and_deletion ) %>% 
  select(-int.surveys_and_deletion) %>% 
  dt_with_modified_options()

```

### Daily enumerator performance

The average survey time for all the data is: **`r round(mean(df_enum_performance$int.survey_time_interval), 0)`** Minutes

```{r, echo = FALSE}

df_enum_performance %>% 
  group_by(district_name, start_date, enumerator_id) %>% 
  summarise(number_of_interviews_done = n(), `average_survey_time(minutes)` = round(mean(int.survey_time_interval, na.rm = TRUE), 0)) %>% 
  dt_enum_performance_options()
```

## Looking into the cleaning log

### Number of issues by issue_id

```{r, echo = FALSE}
df_cl_log %>% 
  group_by(issue_id) %>% 
  summarise(number_of_issues_by_issue_id = n()) %>%
  dt_options_fewcols()
```
### Number of issues by enumerator

```{r, echo = FALSE}
df_cl_log %>% 
  group_by(enumerator_id) %>% 
  summarise(number_of_issues_by_enumerator_id = n()) %>%
  dt_options_fewcols()
```

### Number of issues by enumerator and issue_id

```{r, echo = FALSE}
df_cl_log %>% 
  group_by(enumerator_id, issue_id) %>% 
  summarise(number_of_issues_by_enumerator_and_issue_id = n()) %>%
  dt_options_fewcols()
```

### Enumerators with surveys for deletion

```{r, echo = FALSE}
df_cl_log %>% 
  filter(type == "remove_survey", reviewed == 1, adjust_log != "delete_log") %>% 
  group_by(enumerator_id) %>% 
  summarise(number_of_surveys_for_deletion_by_enumerator = n()) %>%
  dt_options_fewcols()
```

### Map of surveys for deletion

```{r, echo = FALSE, out.width="100%"}
# popup
labels_pts <- ~sprintf(
  "<strong>Status and Name: %s</strong><br/>
      Point Number :  <strong>%s</strong><br/>
      Issue ID :  <strong>%s</strong><br/>
      Issue :  <strong>%s</strong><br/>
      Enumerator ID :  <strong>%s</strong>",
  int.status, point_number, issue_id, issue, enumerator_id
) %>% 
  lapply(htmltools::HTML)

df_cl_log %>% 
  filter(type == "remove_survey", reviewed == 1, adjust_log != "delete_log") %>% 
  group_by(uuid, status, sub_county_name, settlement_name, latitude, longitude) %>% 
  summarise(start_date = paste(start_date, collapse = " : "),
            enumerator_id = paste(enumerator_id, collapse = " : "),
            district_name = paste(district_name, collapse = " : "),
            point_number = paste(point_number, collapse = " : "),
            type = paste(type, collapse = " : "),
            name = paste(name, collapse = " : "),
            current_value = paste(current_value, collapse = " : "),
            value = paste(value, collapse = " : "),
            issue_id = paste(issue_id, collapse = " : "),
            issue = paste(issue, collapse = " : ")
  ) %>% 
  unique() %>% 
  mutate(int.status = ifelse(status == "refugee", 
                             glue("{status}_{settlement_name}"), glue("{status}_{sub_county_name}"))) %>% 
  leaflet() %>% 
  addTiles() %>%
  addCircleMarkers(~longitude,
                   ~latitude,
                   popup = labels_pts,
                   radius = 10,
                   color = "red",
                   stroke = FALSE, fillOpacity = 0.9,
                   label = labels_pts,
                   clusterOptions = markerClusterOptions())
```

